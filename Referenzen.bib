@inproceedings{Milgram1994,
	abstract = {In this paper we discuss Augmented Reality (AR) displays in a general sense, within the context of a Reality-Virtuality (RV) continuum, encompassing a large class of "Mixed Reality" (MR) displays, which also includes Augmented Virtuality (AV). MR displays are defined by means of seven examples of existing display concepts in which real objects and virtual objects are juxtaposed. Essential factors which distinguish different Mixed Reality display systems from each other are presented, first by means of a table in which the nature of the underlying scene, how it is viewed, and the observer's reference to it are compared, and then by means of a three dimensional taxonomic framework, comprising: Extent of World Knowledge (EWK), Reproduction Fidelity (RF) and Extent of Presence Metaphor (EPM). A principal objective of the taxonomy is to clarify terminology issues and to provide a framework for classifying research across different disciplines.},
	archivePrefix = {arXiv},
	arxivId = {NIHMS150003},
	author = {Milgram, Paul and Takemura, Haruo and Utsumi, Akira and Kishino, Fumio},
	booktitle = {Proceedings of the SPIE, Volume 2351, p. 282-292 (1994).},
	doi = {10.1117/12.197321},
	editor = {Das, Hari},
	eprint = {NIHMS150003},
	month = {12},
	pages = {282--292},
	pmid = {11743703},
	title = {{Augmented reality: a class of displays on the reality-virtuality continuum}},
	url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?articleid=981543},
	volume = {2351},
	year = {1994}
}
@inproceedings{Kato1999,
	abstract = {We describe an augmented reality conferencing system which uses the overlay of virtual images on the real world. Remote collaborators are represented on Virtual Monitors which can be freely positioned about a user in space. Users can collaboratively view and interact with virtual objects using a shared virtual whiteboard. This is possible through precise virtual image registration using fast and accurate computer vision techniques and HMD calibration. We propose a method for tracking fiducial markers and a calibration method for optical see-through HMD based on the marker tracking.},
	author = {Kato, H. and Billinghurst, M.},
	booktitle = {Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality (IWAR'99)},
	doi = {10.1109/IWAR.1999.803809},
	isbn = {0-7695-0359-4},
	issn = {16136829},
	pages = {85--94},
	publisher = {IEEE Comput. Soc},
	title = {{Marker tracking and HMD calibration for a video-based augmented reality conferencing system}},
	url = {http://ieeexplore.ieee.org/document/803809/},
	year = {1999}
}
@inproceedings{Cote2013,
address = {London},
author = {C{\^{o}}t{\'{e}}, St{\'{e}}phane and Trudel, Philippe and Desbiens, Marc-Antoine and Gigu{\`{e}}re, Mathieu and Snyder, Rob},
booktitle = {Proceedings of the 13th International Conference on Construction  Applications of Virtual Reality},
title = {{Live mobile panoramic high accuracy augmented reality for engineering and construction}},
year = {2013}
}
@article{Wang2013,
abstract = {During the last two decades, designers have been embracing building information modeling (BIM) to improve the quality of the documentation that is produced as well as constructability. While BIM has become an innate feature of the design process within the construction industry, there have been limited investigations that have examined how it can be integrated into real-time communication on-site. In addressing this gap, this paper proposes a conceptual framework that integrates BIM with augmented reality (AR) so as to enable the physical context of each construction activity or task to be visualized in real-time. To be effective, it is suggested that AR should be ubiquitous (including context awareness) and thus operate in conjunction with tracking and sensing technologies such as radio frequency identification (RFID), laser pointing, sensors and motion tracking.},
author = {Wang, Xiangyu and Love, Peter E.D. and Kim, Mi Jeong and Park, Chan-Sik and Sing, Chun-Pong and Hou, Lei},
doi = {10.1016/J.AUTCON.2012.10.012},
issn = {0926-5805},
journal = {Automation in Construction},
month = {sep},
pages = {37--44},
publisher = {Elsevier},
title = {{A conceptual framework for integrating building information modeling with augmented reality}},
url = {https://www.sciencedirect.com/science/article/pii/S0926580512001793},
volume = {34},
year = {2013}
}
@article{Patraucean2015,
abstract = {Building Information Models (BIMs) are becoming the official standard in the construction industry for encoding, reusing, and exchanging information about structural assets. Automatically generating such representations for existing assets stirs up the interest of various industrial, academic, and governmental parties, as it is expected to have a high economic impact. The purpose of this paper is to provide a general overview of the as-built modelling process, with focus on the geometric modelling side. Relevant works from the Computer Vision, Geometry Processing, and Civil Engineering communities are presented and compared in terms of their potential to lead to automatic as-built modelling.},
author = {Pătrăucean, Viorica and Armeni, Iro and Nahangi, Mohammad and Yeung, Jamie and Haas, Carl},
doi = {10.1016/J.AEI.2015.01.001},
issn = {1474-0346},
journal = {Advanced Engineering Informatics},
month = {apr},
number = {2},
pages = {162--171},
publisher = {Elsevier},
title = {{State of research in automatic as-built modelling}},
url = {https://www.sciencedirect.com/science/article/pii/S1474034615000026},
volume = {29},
year = {2015}
}
@article{Behzadan2015,
abstract = {In Civil Infrastructure System (CIS) applications, the requirement of blending synthetic and physical objects distinguishes Augmented Reality (AR) from other visualization technologies in three aspects: (1) it reinforces the connections between people and objects, and promotes engineers' appreciation about their working context; (2) it allows engineers to perform field tasks with the awareness of both the physical and synthetic environment; and (3) it offsets the significant cost of 3D Model Engineering by including the real world background. This paper reviews critical problems in AR and investigates technical approaches to address the fundamental challenges that prevent the technology from being usefully deployed in CIS applications, such as the alignment of virtual objects with the real environment continuously across time and space; blending of virtual entities with their real background faithfully to create a sustained illusion of co-existence; and the integration of these methods to a scalable and extensible computing AR framework that is openly accessible to the teaching and research community. The research findings have been evaluated in several challenging CIS applications where the potential of having a significant economic and social impact is high. Examples of validation test beds implemented include an AR visual excavator-utility collision avoidance system that enables workers to “see” buried utilities hidden under the ground surface, thus helping prevent accidental utility strikes; an AR post-disaster reconnaissance framework that enables building inspectors to rapidly evaluate and quantify structural damage sustained by buildings in seismic events such as earthquakes or blasts; and a tabletop collaborative AR visualization framework that allows multiple users to observe and interact with visual simulations of engineering processes.},
author = {Behzadan, Amir H. and Dong, Suyang and Kamat, Vineet R.},
doi = {10.1016/J.AEI.2015.03.005},
issn = {1474-0346},
journal = {Advanced Engineering Informatics},
month = {apr},
number = {2},
pages = {252--267},
publisher = {Elsevier},
title = {{Augmented reality visualization: A review of civil infrastructure system applications}},
url = {https://www.sciencedirect.com/science/article/pii/S1474034615000324},
volume = {29},
year = {2015}
}
@article{Olbrich2013,
author = {Olbrich, Manuel and Graf, Holger and Kahn, Svenja and Engelke, Timo and Keil, Jens and Riess, Patrick and Webel, Sabine and Bockholt, Ulrich and Picinbono, Guillaume},
doi = {10.1007/s00371-013-0840-2},
issn = {0178-2789},
journal = {The Visual Computer},
month = {10},
number = {10},
pages = {1093--1105},
publisher = {Springer Berlin Heidelberg},
title = {{Augmented reality supporting user-centric building information management}},
url = {http://link.springer.com/10.1007/s00371-013-0840-2},
volume = {29},
year = {2013}
}
@inproceedings{Arth2009,
author = {Arth, Clemens and Wagner, Daniel and Klopschitz, Manfred and Irschara, Arnold and Schmalstieg, Dieter},
booktitle = {2009 8th IEEE International Symposium on Mixed and Augmented Reality},
doi = {10.1109/ISMAR.2009.5336494},
isbn = {978-1-4244-5390-0},
month = {oct},
pages = {73--82},
publisher = {IEEE},
title = {{Wide area localization on mobile phones}},
url = {http://ieeexplore.ieee.org/document/5336494/},
year = {2009}
}
@article{Wei2015,
author = {Wei, Benchang and Guan, Tao and Duan, Liya and Yu, Junqing and Mao, Tan},
doi = {10.1007/s00530-014-0364-2},
issn = {0942-4962},
journal = {Multimedia Systems},
month = {jul},
number = {4},
pages = {381--399},
publisher = {Springer Berlin Heidelberg},
title = {{Wide area localization and tracking on camera phones for mobile augmented reality systems}},
url = {http://link.springer.com/10.1007/s00530-014-0364-2},
volume = {21},
year = {2015}
}
@inproceedings{Klein2009,
author = {Klein, Georg and Murray, David},
booktitle = {2009 8th IEEE International Symposium on Mixed and Augmented Reality},
doi = {10.1109/ISMAR.2009.5336495},
isbn = {978-1-4244-5390-0},
month = {10},
pages = {83--86},
publisher = {IEEE},
title = {{Parallel Tracking and Mapping on a camera phone}},
url = {http://ieeexplore.ieee.org/document/5336495/},
year = {2009}
}
@inproceedings{Reitmayr2007,
author = {Reitmayr, Gerhard and Drummond, Tom W.},
booktitle = {2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality},
doi = {10.1109/ISMAR.2007.4538842},
isbn = {978-1-4244-1749-0},
month = {nov},
pages = {1--9},
publisher = {IEEE},
title = {{Initialisation for Visual Tracking in Urban Environments}},
url = {http://ieeexplore.ieee.org/document/4538842/},
year = {2007}
}
@inproceedings{Billinghurst2000,
author = {Billinghurst, M. and Poupyrev, I. and Kato, H. and May, R.},
booktitle = {2000 IEEE International Conference on Multimedia and Expo. ICME2000. Proceedings. Latest Advances in the Fast Changing World of Multimedia (Cat. No.00TH8532)},
doi = {10.1109/ICME.2000.871085},
isbn = {0-7803-6536-4},
pages = {1641--1644},
publisher = {IEEE},
title = {{Mixing realities in Shared Space: an augmented reality interface for collaborative computing}},
url = {http://ieeexplore.ieee.org/document/871085/},
volume = {3},
year = {2000}
}
@inproceedings{Becker2007,
author = {Becker, Mario and Bleser, Gabriele and Pagani, Alain and Stricker, Didier and Wuest, Harald},
booktitle = {2007 3DTV Conference},
doi = {10.1109/3DTV.2007.4379440},
isbn = {978-1-4244-0721-7},
month = {may},
pages = {1--4},
publisher = {IEEE},
title = {{An Architecture for Prototyping and Application Development of Visual Tracking Systems}},
url = {http://ieeexplore.ieee.org/document/4379440/},
year = {2007}
}
@article{Wang2013a,
abstract = {During the last two decades, designers have been embracing building information modeling (BIM) to improve the quality of the documentation that is produced as well as constructability. While BIM has become an innate feature of the design process within the construction industry, there have been limited investigations that have examined how it can be integrated into real-time communication on-site. In addressing this gap, this paper proposes a conceptual framework that integrates BIM with augmented reality (AR) so as to enable the physical context of each construction activity or task to be visualized in real-time. To be effective, it is suggested that AR should be ubiquitous (including context awareness) and thus operate in conjunction with tracking and sensing technologies such as radio frequency identification (RFID), laser pointing, sensors and motion tracking.},
author = {Wang, Xiangyu and Love, Peter E.D. and Kim, Mi Jeong and Park, Chan-Sik and Sing, Chun-Pong and Hou, Lei},
doi = {10.1016/J.AUTCON.2012.10.012},
issn = {0926-5805},
journal = {Automation in Construction},
month = {sep},
pages = {37--44},
publisher = {Elsevier},
title = {{A conceptual framework for integrating building information modeling with augmented reality}},
url = {https://www.sciencedirect.com/science/article/pii/S0926580512001793},
volume = {34},
year = {2013}
}
@article{Opperman2015,
	abstract = {Being able to explore vast outdoor scenery, cityscapes, or the interior of virtual buildings is the state of the art for video gamers. But city planners and building owners usually still have to settle with blueprints, rendered movies, and miniature models. Fraunhofer FIT's innovative “Auto AR” system allows the user to experience virtual building models on site, almost as if they were already built.},
	author = {Opperman, Leif},
	journal = {ERCIM News 103 October 2015},
	pages = {18--19},
	title = {{Auto AR - In Situ Visualization for Building Information Modelling}},
	url = {https://ercim-news.ercim.eu/images/stories/EN103/EN103-web.pdf},
	year = {2015}
}
@online{DAQRI2018,
	author = {DAQRI},
	title = {{DAQRI Smart Glasses}},
	year = {2018},
	month = {10},
	url = {https://daqri.com/products/smart-glasses/},
	urldate = {2018-10-24}}
}